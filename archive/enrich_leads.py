#!/usr/bin/env python3
"""
Instagram Lead Enrichment Workflow
–û–±–æ–≥–∞—â–µ–Ω–∏–µ –ª–∏–¥–æ–≤ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Instagram
"""

import os
import time
from pathlib import Path
from dotenv import load_dotenv
from modules.google_search import GoogleSearchClient
from modules.instagram_scraper import InstagramScraper
from modules.csv_handler import CSVHandler

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


class LeadEnricher:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –ª–∏–¥–æ–≤"""

    def __init__(
        self,
        rapidapi_key: str,
        apify_key: str,
        enrich_profiles: bool = True,
        delay_between_requests: float = 2.0
    ):
        self.google_client = GoogleSearchClient(rapidapi_key)
        self.instagram_scraper = InstagramScraper(apify_key) if enrich_profiles else None
        self.csv_handler = CSVHandler()
        self.enrich_profiles = enrich_profiles
        self.delay = delay_between_requests

    def enrich_single_lead(self, name: str, email: str) -> dict:
        """
        –û–±–æ–≥–∞—Ç–∏—Ç—å –æ–¥–Ω–æ–≥–æ –ª–∏–¥–∞

        Args:
            name: –ò–º—è –ª–∏–¥–∞
            email: Email –ª–∏–¥–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        result = {
            'instagram_url': None,
            'profile_data': None,
            'status': 'not_found'
        }

        # –®–∞–≥ 1: –ù–∞–π—Ç–∏ Instagram URL —á–µ—Ä–µ–∑ Google
        print(f"  üîç –ü–æ–∏—Å–∫ Instagram –ø—Ä–æ—Ñ–∏–ª—è...")
        instagram_url = self.google_client.find_instagram_profile(name, email)

        if not instagram_url:
            result['status'] = 'not_found'
            print(f"  ‚úó Instagram –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return result

        result['instagram_url'] = instagram_url
        print(f"  ‚úì –ù–∞–π–¥–µ–Ω: {instagram_url}")

        # –®–∞–≥ 2: –û–±–æ–≥–∞—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Apify (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if self.enrich_profiles and self.instagram_scraper:
            print(f"  üîé –û–±–æ–≥–∞—â–∞—é –ø—Ä–æ—Ñ–∏–ª—å —á–µ—Ä–µ–∑ Apify...")
            time.sleep(self.delay)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ Apify –∑–∞–ø—Ä–æ—Å–æ–º

            profile_data = self.instagram_scraper.scrape_profile(instagram_url)

            if profile_data:
                result['profile_data'] = profile_data
                result['status'] = 'enriched'
                print(f"  ‚úì –û–±–æ–≥–∞—â–µ–Ω: @{profile_data['username']} ({profile_data['followers_count']} followers)")
            else:
                result['status'] = 'found_not_enriched'
                print(f"  ‚ö† –ù–∞–π–¥–µ–Ω, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–æ–≥–∞—Ç–∏—Ç—å")
        else:
            result['status'] = 'found_not_enriched'

        return result

    def enrich_csv(
        self,
        input_path: str,
        output_path: str = None,
        name_column: str = 'Person - Name',
        email_column: str = 'Person - Email - Work',
        max_rows: int = None
    ):
        """
        –û–±–æ–≥–∞—Ç–∏—Ç—å CSV —Ñ–∞–π–ª

        Args:
            input_path: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV
            output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            name_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –∏–º–µ–Ω–µ–º
            email_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å email
            max_rows: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        print(f"\nüìÇ –ó–∞–≥—Ä—É–∂–∞—é CSV: {input_path}")
        df = self.csv_handler.load_csv(input_path)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
        df = self.csv_handler.prepare_enrichment_columns(df)

        total_rows = len(df) if not max_rows else min(len(df), max_rows)
        print(f"üìä –í—Å–µ–≥–æ –ª–∏–¥–æ–≤: {len(df)}")
        print(f"üéØ –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_rows}\n")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏–¥–∞
        for index, row in df.iterrows():
            if max_rows and index >= max_rows:
                break

            name = row.get(name_column, '')
            email = row.get(email_column, '')

            print(f"[{index + 1}/{total_rows}] {name} ({email})")

            if not name and not email:
                print(f"  ‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ: –Ω–µ—Ç –∏–º–µ–Ω–∏ –∏ email")
                self.csv_handler.mark_row_as_not_found(df, index, "No name/email")
                continue

            try:
                # –û–±–æ–≥–∞—â–∞–µ–º –ª–∏–¥–∞
                result = self.enrich_single_lead(name, email)

                # –û–±–Ω–æ–≤–ª—è–µ–º DataFrame
                if result['status'] == 'not_found':
                    self.csv_handler.mark_row_as_not_found(df, index)
                else:
                    self.csv_handler.update_row_with_instagram_data(
                        df, index,
                        result['instagram_url'],
                        result['profile_data']
                    )

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(self.delay)

            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞: {e}")
                self.csv_handler.mark_row_as_not_found(df, index, f"Error: {str(e)}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not output_path:
            output_path = self.csv_handler.generate_output_filename(input_path)

        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {output_path}")
        self.csv_handler.save_csv(df, output_path)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = self.csv_handler.get_statistics(df)
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ: {stats['total']}")
        print(f"  –û–±–æ–≥–∞—â–µ–Ω–æ: {stats['enriched']}")
        print(f"  –ù–∞–π–¥–µ–Ω–æ (–±–µ–∑ –æ–±–æ–≥–∞—â–µ–Ω–∏—è): {stats['found_not_enriched']}")
        print(f"  –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {stats['not_found']}")
        print(f"  Success Rate: {stats['success_rate']:.1f}%")

        return output_path, stats


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è CLI –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    import argparse

    parser = argparse.ArgumentParser(description='–û–±–æ–≥–∞—â–µ–Ω–∏–µ –ª–∏–¥–æ–≤ Instagram –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('input', help='–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª')
    parser.add_argument('-o', '--output', help='–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    parser.add_argument('--no-enrich', action='store_true', help='–¢–æ–ª—å–∫–æ –Ω–∞–π—Ç–∏ URLs, –Ω–µ –æ–±–æ–≥–∞—â–∞—Ç—å')
    parser.add_argument('--max-rows', type=int, help='–ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--delay', type=float, default=2.0, help='–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)')

    args = parser.parse_args()

    # API –∫–ª—é—á–∏ –∏–∑ .env
    rapidapi_key = os.getenv('RAPIDAPI_KEY')
    apify_key = os.getenv('APIFY_API_KEY')

    if not rapidapi_key:
        print("‚ùå RAPIDAPI_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
        return

    if not args.no_enrich and not apify_key:
        print("‚ùå APIFY_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
        return

    # –°–æ–∑–¥–∞–µ–º enricher
    enricher = LeadEnricher(
        rapidapi_key=rapidapi_key,
        apify_key=apify_key,
        enrich_profiles=not args.no_enrich,
        delay_between_requests=args.delay
    )

    # –û–±–æ–≥–∞—â–∞–µ–º
    enricher.enrich_csv(
        input_path=args.input,
        output_path=args.output,
        max_rows=args.max_rows
    )


if __name__ == '__main__':
    main()
